{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import f\n",
    "from scipy.special import betainc\n",
    "from scipy.stats import norm, f, t\n",
    "from scipy.ndimage import rotate\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "subjects = 57"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "anatomical = nib.load('Unthresholded/neurosynth/anatomical.nii.gz').get_fdata()\n",
    "spmT = nib.load('Unthresholded/neurosynth/TMap_1.nii.gz').get_fdata()\n",
    "mask = nib.load('Unthresholded/neurosynth/mask.nii.gz').get_fdata()\n",
    "spmT_masked=mask*spmT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGPV Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute z-score from alpha\n",
    "def z_score_from_alpha(alpha, tail='two-sided'):\n",
    "    \"\"\"\n",
    "    Calculates the z-score from a given alpha value.\n",
    "\n",
    "    Parameters:\n",
    "    alpha (float): Significance level (e.g., 0.05).\n",
    "    tail (str): Type of test tail ('two-sided', 'left', or 'right').\n",
    "                  Defaults to 'two-sided'.\n",
    "\n",
    "    Returns:\n",
    "    float: Z-score corresponding to the alpha value.\n",
    "    \"\"\"\n",
    "    if tail == 'two-sided':\n",
    "        z = norm.ppf(1 - alpha/2)\n",
    "    elif tail == 'left':\n",
    "        z = norm.ppf(alpha)\n",
    "    elif tail == 'right':\n",
    "         z = norm.ppf(1 - alpha)\n",
    "    else:\n",
    "        raise ValueError(\"tail must be 'two-sided', 'left', or 'right'\")\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for second generation p-value calculations\n",
    "def calculate_second_gen_p_value(observed_effect, null_hypothesis, effect_interval, n, alpha, df, verbose=True):\n",
    "    \"\"\"\n",
    "    Calculate second-generation p-value for neuroimaging data\n",
    "\n",
    "    Parameters:\n",
    "        observed_effect (float): Estimated effect size from neuroimaging analysis - Contrast_img (z scores)\n",
    "        null_hypothesis (float): Point null hypothesis value (0)\n",
    "        effect_interval (float): Interval of practically equivalent effects (User provides this - we need to test this value)\n",
    "        f2 (float): Cohen's f-squared effect size\n",
    "        n (int): Sample size\n",
    "        alpha (float): Significance level\n",
    "        df (int): Degrees of freedom\n",
    "        verbose (bool): If True, print intermediate calculations. If False, suppress output.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (delta_p, interpretation)\n",
    "    \"\"\"\n",
    "    def vprint(*args, **kwargs):\n",
    "        if verbose:\n",
    "            print(*args, **kwargs)\n",
    "\n",
    "    vprint(f'N: {n}')\n",
    "    vprint(f'alpha: {alpha}')\n",
    "    vprint(f'df: {df}')\n",
    "\n",
    "    #vprint(f'Cohens f2: {f2}')\n",
    "    #d = 2 * np.sqrt(f2) #in the case of 2 means (a t-test) according to Cohen's power book\n",
    "    #vprint(f'Cohens d: {d}\\n')\n",
    "\n",
    "    vprint(f'Z-score: {observed_effect}')\n",
    "    #t_val = observed_effect / (d * np.sqrt(n))\n",
    "    #vprint(f'T-score: {t_val}')\n",
    "    \n",
    "    if df == 2:\n",
    "        std = z_score_from_alpha(alpha, tail='two-sided')\n",
    "    elif df == 1:\n",
    "        std = z_score_from_alpha(alpha, tail='right')\n",
    "    else:\n",
    "        vprint('error - no df specified')\n",
    "        std = 1  # fallback to prevent crash\n",
    "    \n",
    "    vprint(f'SD: {std}')\n",
    "    std_error = std / np.sqrt(n - df)\n",
    "    vprint(f'SE: {std_error}')\n",
    "\n",
    "    ci_lower = observed_effect - std_error\n",
    "    ci_upper = observed_effect + std_error\n",
    "    vprint(f'Confidence Interval: [{ci_lower},{ci_upper}]\\n')\n",
    "\n",
    "    ###TEST\n",
    "    #effect_interval = effect_interval / (d * np.sqrt(n))\n",
    "    \n",
    "    vprint(f'Null Hypothesis: {null_hypothesis}')\n",
    "    vprint(f'Effect Interval Test Value: {effect_interval}')\n",
    "    interval_lower = null_hypothesis - effect_interval\n",
    "    interval_upper = null_hypothesis + effect_interval\n",
    "    vprint(f'Null Interval: [{interval_lower},{interval_upper}]\\n')\n",
    "    \n",
    "    if ci_upper <= interval_upper and ci_lower >= interval_lower:\n",
    "        delta_p = 1.0\n",
    "        interpretation = 'The data supports the null hypothesis - not scientifically or clinically meaningful'\n",
    "    elif ci_upper < interval_lower or ci_lower > interval_upper:\n",
    "        delta_p = 0.0\n",
    "        interpretation = 'The data supports an alternative hypothesis that is scientifically OR clinically meaningful'\n",
    "    elif (ci_upper - ci_lower) > (2 * (interval_upper - interval_lower)):\n",
    "        delta_p = 0.5\n",
    "        interpretation = 'Data is strictly inconclusive'\n",
    "    else:\n",
    "        overlap_lower = max(ci_lower, interval_lower)\n",
    "        overlap_upper = min(ci_upper, interval_upper)\n",
    "        delta_p = (overlap_upper - overlap_lower) / (ci_upper - ci_lower)\n",
    "        interpretation = 'Partial evidence, some consistency with null'\n",
    "\n",
    "    vprint(f'Second Gen p-value: {delta_p}') \n",
    "    vprint(f'Interpretation: {interpretation}')  \n",
    "\n",
    "    return delta_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 57\n",
      "alpha: 0.05\n",
      "df: 1\n",
      "Z-score: 3.145\n",
      "SD: 1.644853626951472\n",
      "SE: 0.219802811551603\n",
      "Confidence Interval: [2.925197188448397,3.364802811551603]\n",
      "\n",
      "Null Hypothesis: 0\n",
      "Effect Interval Test Value: 3\n",
      "Null Interval: [-3,3]\n",
      "\n",
      "Second Gen p-value: 0.17015890521045832\n",
      "Interpretation: Partial evidence, some consistency with null\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17015890521045832"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###TEST\n",
    "calculate_second_gen_p_value(observed_effect = 3.145, #t value\n",
    "                            null_hypothesis = 0, \n",
    "                            effect_interval = 3, #95% CI of t distribution\n",
    "                            n = subjects, \n",
    "                            alpha = 0.05, \n",
    "                            df = 1, #1 -tailed\n",
    "                            verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
